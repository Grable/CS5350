from enum import unique
import numpy as np
import pandas as pd
import math
import copy

training_dataset_path = "../CS5350/train.csv"
testing_dataset_path = "../CS5350/test.csv"
prob1_dataset_path = "../CS5350/prob1.csv"
tennis_dataset_path = "../CS5350/tennis.csv"
bank_train_dataset_path = "../CS5350/bank_train.csv"


def ME(data):
    targets = [row[4] for row in data]
    unique = set(targets)
    freq = {i: targets.count(i) for i in unique}
    majority_error = {y: abs(frequency / len(data)) for y, frequency in freq.items()}
    val = min(majority_error.values())
    return val


def gini(data):
    targets = [row[4] for row in data]
    unique = set(targets)
    freq = {i: targets.count(i) for i in unique}
    gindex = {y: (frequency / len(data)) for y, frequency in freq.items()}
    val = 0
    for x in gindex.values():
        val += x * x
    return 1 - val


def entropy(data):
    targets = [row[15] for row in data]
    unique = set(targets)
    freq = {i: targets.count(i) for i in unique}
    entropy = {
        y: -(frequency / len(data)) * math.log(frequency / len(data), 2)
        for y, frequency in freq.items()
    }
    val = sum(entropy.values())
    return val


def _gain(data, ind):
    gain = 0
    attribute_val = [i[ind] for i in data]
    unique_att_val = set(attribute_val)

    # the gain begins...
    for x in unique_att_val:
        # probability math
        length = len(attribute_val)
        frequency = attribute_val.count(x)
        probability = frequency / length

        ind_only_data = [i for i in data if i[ind] == x]
        ind_entropy = entropy(ind_only_data)
        # increment gain based on entropy * probability using this particular attribute
        gain += probability * ind_entropy
    overall_entropy = entropy(data)
    return overall_entropy - gain


def best_att(data):
    max_gain = 0
    max_gain_ind = -1
    attribute_count = len(data[0]) - 1  # not including the label value
    for i in range(attribute_count):
        gain = _gain(data, i)
        # take largest gain of all attributes
        if gain > max_gain:
            max_gain = gain
            max_gain_ind = i
    return max_gain_ind


def build_tree(data, columns):
    attribute_count = len(data[0]) - 1  # not including the label value
    if attribute_count == 0:
        return

    targets = set([row[15] for row in data])

    if len(targets) == 1:
        return targets.pop()

    max_gain_att_ind = best_att(data)

    tree = {columns[max_gain_att_ind]: {}}  # create tree as dictionary

    # now the fun recursion begins
    attribute_val = set([i[max_gain_att_ind] for i in data])

    for val in attribute_val:
        val_data = [i for i in data if i[max_gain_att_ind] == val]
        filtered_tree = build_tree(val_data, columns)

        # associate filtered tree with "parent"
        tree[columns[max_gain_att_ind]][val] = filtered_tree
    return tree


def visualize(root, indent=0):
    if type(root) == dict:
        for k, v in root.items():
            print(" " * indent + f"{k}:")
            visualize(v, indent + 2)
    else:
        print(" " * indent + repr(root))


def gini_gain(data, ind):
    gain = 0
    attribute_val = [i[ind] for i in data]
    unique_att_val = set(attribute_val)

    # the gain begins...
    for x in unique_att_val:
        # probability math
        length = len(attribute_val)
        frequency = attribute_val.count(x)
        probability = frequency / length

        ind_only_data = [i for i in data if i[ind] == x]
        ind_entropy = gini(ind_only_data)
        # increment gain based on entropy * probability using this particular attribute
        gain += probability * ind_entropy
    overall_entropy = gini(data)
    return overall_entropy - gain


def best_att_gini(data):
    max_gain = 0
    max_gain_ind = -1
    attribute_count = len(data[0]) - 1  # not including the label value
    for i in range(attribute_count):
        gain = gini_gain(data, i)
        # take largest gain of all attributes
        if gain > max_gain:
            max_gain = gain
            max_gain_ind = i
    return max_gain_ind


def build_tree_gini(data, columns):
    attribute_count = len(data[0]) - 1  # not including the label value
    if attribute_count == 0:
        return

    targets = set([row[4] for row in data])

    if len(targets) == 1:
        return targets.pop()

    max_gain_att_ind = best_att_gini(data)

    tree = {columns[max_gain_att_ind]: {}}  # create tree as dictionary

    # now the fun recursion begins
    attribute_val = set([i[max_gain_att_ind] for i in data])

    for val in attribute_val:
        val_data = [i for i in data if i[max_gain_att_ind] == val]
        filtered_tree = build_tree_gini(val_data, columns)

        # associate filtered tree with "parent"
        tree[columns[max_gain_att_ind]][val] = filtered_tree
    return tree


def ME_gain(data, ind):
    gain = 0
    attribute_val = [i[ind] for i in data]
    unique_att_val = set(attribute_val)

    # the gain begins...
    for x in unique_att_val:
        length = len(attribute_val)
        frequency = attribute_val.count(x)
        probability = frequency / length
        ind_only_data = [i for i in data if i[ind] == x]
        ind_entropy = ME(ind_only_data)
        # increment gain based on entropy * probability using this particular attribute
        gain += probability * ind_entropy
    overall_entropy = ME(data)
    return overall_entropy - gain


def best_att_ME(data):
    max_gain = 0
    max_gain_ind = -1
    attribute_count = len(data[0]) - 1  # not including the label value
    for i in range(attribute_count):
        gain = ME_gain(data, i)
        # take largest gain of all attributes
        if gain > max_gain:
            max_gain = gain
            max_gain_ind = i
    return max_gain_ind


def build_tree_ME(data, columns):
    attribute_count = len(data[0]) - 1  # not including the label value
    if attribute_count == 0:
        return

    targets = set([row[4] for row in data])

    if len(targets) == 1:
        return targets.pop()

    max_gain_att_ind = best_att_ME(data)

    tree = {columns[max_gain_att_ind]: {}}  # create tree as dictionary

    # now the fun recursion begins
    attribute_val = set([i[max_gain_att_ind] for i in data])

    for val in attribute_val:
        val_data = [i for i in data if i[max_gain_att_ind] == val]
        filtered_tree = build_tree_ME(val_data, columns)

        # associate filtered tree with "parent"
        tree[columns[max_gain_att_ind]][val] = filtered_tree
    return tree


# for training data
# with open(training_dataset_path, "r") as f:
#     train = []

#     for line in f:
#         train.append(line.strip().split(","))

#     targets = [row[6] for row in train]
#     unique_targets = set(targets)
#     columns = ["buying", "maint", "doors", "persons", "lug_boots", "safety", "label"]
# train_tree = build_tree(train, columns)
# print("TRAINING TREE")
# visualize(train_tree)

# for testing data, identical code, different datasets
# with open(testing_dataset_path, "r") as f1:
#     test = []

#     for line in f1:
#         test.append(line.strip().split(","))
#     targets = [row[6] for row in test]
#     columns = ["buying", "maint", "doors", "persons", "lug_boots", "safety", "label"]
# test_tree = build_tree(test, columns)
# print("\n TESTING TREE")
# print(test_tree)

# with open(prob1_dataset_path, "r") as p1:
#     prob1 = []

#     for line in p1:
#         prob1.append(line.strip().split(","))
#     targets = [row[4] for row in prob1]
#     columns = ["x1", "x2", "x3", "x4", "y"]
#     prob1_tree = build_tree(prob1, columns)
#     print("PROB1")
#     print(prob1_tree)

# with open(tennis_dataset_path, "r") as p1:
#     tennis = []

#     for line in p1:
#         tennis.append(line.strip().split(","))
#     targets = [row[4] for row in tennis]
#     columns = ["Outlook", "Temperature", "Humidity", "Wind", "Play?"]
#     tennis_tree = build_tree(tennis, columns)
#     print("tennis")
#     print(tennis_tree)

with open(bank_train_dataset_path, "r") as b1:
    bank_train = []

    for line in b1:
        bank_train.append(line.strip().split(","))
    targets = [row[15] for row in bank_train]
    columns = [
        "Age",
        "Job",
        "Marital",
        "Education",
        "Default",
        "Balance",
        "Housing",
        "Loan",
        "Contact",
        "Day",
        "Month",
        "Duration",
        "Campaign",
        "Pdays",
        "Previous",
        "Poutcome",
        "y",
    ]
    bank_train_tree = build_tree(bank_train, columns)
    print("bank_train")
    print(bank_train_tree)
